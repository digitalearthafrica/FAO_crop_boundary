{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements prediction of field extent and boundary probabilities using Planet RGB chunks with validation data available. The prediction uses [FracTAL ResUNet model](https://www.mdpi.com/2072-4292/13/11/2197) and [pre-trained model weights](https://arxiv.org/abs/2201.04771). Results are exported as geotiffs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from mxnet import image\n",
    "from glob import glob\n",
    "# import imageio.v2 as imageio\n",
    "from osgeo import gdal, osr\n",
    "import sys\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "# add existing and decode modules to system path\n",
    "module_paths=['decode/FracTAL_ResUNet/models/semanticsegmentation',\n",
    "             'decode/FracTAL_ResUNet/nn/loss']\n",
    "for module_path in module_paths:\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions from modules\n",
    "from FracTAL_ResUNet import FracTAL_ResUNet_cmtsk\n",
    "from datasets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for model architecture\n",
    "n_filters = 32\n",
    "depth = 6\n",
    "n_classes = 1\n",
    "batch_size = 5\n",
    "codes_to_keep = [1]\n",
    "ctx_name = 'cpu'\n",
    "gpu_id = 0\n",
    "boundary_kernel_size = (2,2)\n",
    "\n",
    "# other parameters\n",
    "country = 'Rwanda'\n",
    "CPU_COUNT = cpu_count()\n",
    "srs = osr.SpatialReference()\n",
    "srs.ImportFromEPSG(3857)\n",
    "\n",
    "# folder of input RGB chunk geotiffs\n",
    "input_folder='../0_Data_preparation/results/RGB_chunks'\n",
    "# folder of validation chunks\n",
    "groundtruth_folder='../0_Data_preparation/results/groundtruth'\n",
    "# folder to store output model predictions\n",
    "out_folder='results'\n",
    "\n",
    "# pre-trained model weights\n",
    "# trained_model='model_weights/Planet_france.params' # trained and fine-tuned on planet data of France\n",
    "trained_model='model_weights/Planet_pretrained-france_finetuned-india.params' # trained on planet data of France and fine-tuned on India\n",
    "# trained_model = 'model_weights/Airbus_pretrained-france_finetuned-india.params' # trained and fine-tuned on SPOT data of France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(out_folder):\n",
    "    os.makedirs(out_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify RGB chunks with validation data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 123 groundtruth chunks\n"
     ]
    }
   ],
   "source": [
    "# extract chunk ids of validation data\n",
    "gt_bound_names=glob(groundtruth_folder+'/'+country+'*crop_field_bound*.tif')\n",
    "print('Found {} groundtruth chunks'.format(len(gt_bound_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 738 RGB images\n"
     ]
    }
   ],
   "source": [
    "# find Planet RGB chunks corresponding to validation chunks\n",
    "image_names=[]\n",
    "for gt_bound_name in gt_bound_names:\n",
    "    # extract id of validation chunk\n",
    "    chunk_id=os.path.basename(gt_bound_name)[:-4].split('_')[-2:]\n",
    "    image_list=glob(os.path.join(input_folder,country+'*'+'_'.join(chunk_id)+'.tif'))\n",
    "    if len(image_list)<1:\n",
    "        print('no RGB found for chunk')\n",
    "    else:\n",
    "        for img in image_list:\n",
    "            image_names.append(img)\n",
    "print('Found {} RGB images'.format(len(image_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "test_dataset = Planet_Dataset_No_labels(image_names=image_names)\n",
    "\n",
    "# Loads data from a dataset and create mini batches\n",
    "# test_dataloader = gluon.data.DataLoader(test_dataset, batch_size=batch_size,num_workers=CPU_COUNT) # might encounter 'connection refused' issue\n",
    "test_dataloader = gluon.data.DataLoader(test_dataset, batch_size=batch_size,num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained model weights and run inference in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:= 0, nfilters: 32, nheads::8, widths::1\n",
      "depth:= 1, nfilters: 64, nheads::16, widths::1\n",
      "depth:= 2, nfilters: 128, nheads::32, widths::1\n",
      "depth:= 3, nfilters: 256, nheads::64, widths::1\n",
      "depth:= 4, nfilters: 512, nheads::128, widths::1\n",
      "depth:= 5, nfilters: 1024, nheads::256, widths::1\n",
      "depth:= 6, nfilters: 512, nheads::256, widths::1\n",
      "depth:= 7, nfilters: 256, nheads::128, widths::1\n",
      "depth:= 8, nfilters: 128, nheads::64, widths::1\n",
      "depth:= 9, nfilters: 64, nheads::32, widths::1\n",
      "depth:= 10, nfilters: 32, nheads::16, widths::1\n"
     ]
    }
   ],
   "source": [
    "# Set MXNet ctx\n",
    "if ctx_name == 'cpu':\n",
    "    ctx = mx.cpu()\n",
    "elif ctx_name == 'gpu':\n",
    "    ctx = mx.gpu(gpu_id)\n",
    "\n",
    "# initialise model\n",
    "model = FracTAL_ResUNet_cmtsk(nfilters_init=n_filters, depth=depth, NClasses=n_classes)\n",
    "\n",
    "# load pre-trained model parameters\n",
    "model.load_parameters(trained_model, ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [16:26<00:00,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 36min 57s, sys: 8min 55s, total: 1h 45min 52s\n",
      "Wall time: 16min 26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# run model\n",
    "for batch_i, img_data in enumerate(tqdm(test_dataloader)):\n",
    "    \n",
    "    # extract batch data\n",
    "    imgs,id_dates,geotrans=img_data\n",
    "    rows, cols= imgs.shape[2],imgs.shape[3]\n",
    "\n",
    "    # make a copy if the variable currently lives in the wrong context\n",
    "    imgs = imgs.as_in_context(ctx)\n",
    "\n",
    "    # predicted outputs: field extent probability, field boundary probability and distance to boundary\n",
    "    logits, bound, dist = model(imgs)\n",
    "\n",
    "    # export predictions for all images in the batch\n",
    "    bt_size=id_dates.asnumpy().shape[0]\n",
    "    for i in range(bt_size):\n",
    "        id_date=id_dates[i,:].asnumpy().astype(int)\n",
    "        str_id_date=[str(id_date[0])] # year\n",
    "        str_id_date.append(str(id_date[1]).zfill(2)) # month\n",
    "        str_id_date.extend([str(s).zfill(3) for s in id_date[2:]]) # zfill rows and cols so that output files also have uniform file name length\n",
    "        gt=geotrans[i,:].asnumpy()\n",
    "        \n",
    "        outname_extent=os.path.join(out_folder,country+'_extent_prob_'+'_'.join(str_id_date)+'.tif')\n",
    "        prj=srs.ExportToWkt()\n",
    "        export_geotiff(outname_extent,logits[1,:,:].asnumpy().squeeze(),gt,prj,gdal.GDT_Float32)\n",
    "\n",
    "        outname_bound=os.path.join(out_folder,country+'_bound_prob_'+'_'.join(str_id_date)+'.tif')\n",
    "        export_geotiff(outname_bound,bound[1,:,:].asnumpy().squeeze(),gt,prj,gdal.GDT_Float32)\n",
    "    \n",
    "#         outname_dist=os.path.join(out_folder,country+'_distance'+'_'.join(str_id_date)+'.tif')\n",
    "#         export_geotiff(outname_dist,dist[1,:,:].asnumpy().squeeze(),gt,prj,gdal.GDT_Float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "4dce633ad74794d18e744ff4895033c1217399eea64af39aea26b4d3f3272ece"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
