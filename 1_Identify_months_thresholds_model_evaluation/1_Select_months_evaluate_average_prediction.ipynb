{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook evaluates field extend and boundary predictions against validation data, uses the validation results to select the best performing months, and evaluates the consensus/averaged predictions from the selected months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imageio.v2 as imageio\n",
    "import os\n",
    "from glob import glob\n",
    "import sys\n",
    "from osgeo import gdal,osr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions from modules\n",
    "from datasets import export_geotiff\n",
    "from evaluation import Calculate_IoUs,get_accuracy_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction and ground truth folders\n",
    "prediction_folder='results'\n",
    "groundtruth_folder='../0_Data_preparation/results/groundtruth'\n",
    "\n",
    "# output folder to store averaged results\n",
    "out_folder='results/averaged'\n",
    "\n",
    "# all candidate image months as strings\n",
    "# str_months=['02','04','06','08','10','12']\n",
    "str_months=['03','04','08','10','11','12']\n",
    "\n",
    "str_year='2021'\n",
    "# country = 'Mozambique'\n",
    "country = 'Rwanda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(out_folder):\n",
    "    os.makedirs(out_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify predicted and ground truth files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 738 field exent probability images\n",
      "Found 123 ground truth field exent images\n",
      "Found 123 ground truth field boundary images\n"
     ]
    }
   ],
   "source": [
    "# predicted exent probabilities for all months\n",
    "files_extent_predictions=glob(prediction_folder+'/'+country+'*extent_prob_*.tif')\n",
    "print('Found {} field exent probability images'.format(len(files_extent_predictions)))\n",
    "\n",
    "# ground truth field exent\n",
    "files_extent_true=glob(groundtruth_folder+'/'+country+'*crop_field_extent*.tif')\n",
    "print('Found {} ground truth field exent images'.format(len(files_extent_true)))\n",
    "\n",
    "# ground truth field boundary\n",
    "files_boundaries_true=glob(groundtruth_folder+'/'+country+'*crop_field_bound*.tif')\n",
    "print('Found {} ground truth field boundary images'.format(len(files_boundaries_true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of predictions for all months - OA, F1 and MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy:  {'03': 0.729652956229998, '04': 0.7240467230362735, '08': 0.7209047786857291, '10': 0.7231197685498895, '11': 0.7312427565828762, '12': 0.723182380309055}\n",
      "mean F1 score:  {'03': 0.8186620063153506, '04': 0.8124161784649712, '08': 0.8096760266082574, '10': 0.8131651103133967, '11': 0.8197450286835098, '12': 0.8115618585923122}\n",
      "mean MCC:  {'03': 0.24091206986578043, '04': 0.24440012200501474, '08': 0.23878090579471944, '10': 0.2456711636626551, '11': 0.23800338966525164, '12': 0.2537885513573362}\n",
      "The three months with highest MCCs:  [('12', 0.2537885513573362), ('10', 0.2456711636626551), ('04', 0.24440012200501474)]\n"
     ]
    }
   ],
   "source": [
    "# initialise accuracy scores for all months\n",
    "mean_accuracy={str_month:[] for str_month in str_months}\n",
    "mean_f1={str_month:[] for str_month in str_months}\n",
    "mean_mcc={str_month:[] for str_month in str_months}\n",
    "\n",
    "# loop for all months\n",
    "for str_month in str_months:\n",
    "    # list of chunk ids\n",
    "    chunk_ids=[]\n",
    "    for file_extent_true in files_extent_true:\n",
    "        # chunk id\n",
    "        chunk_id='_'.join(os.path.basename(file_extent_true)[:-4].split('_')[-2:])\n",
    "        chunk_ids.append(chunk_id)\n",
    "        # read in ground truth extent file\n",
    "        extent_true=imageio.imread(file_extent_true)\n",
    "        # read in corresponding groundtruth boundary file\n",
    "        boundary_true=imageio.imread(file_extent_true.replace('extent','bound'))\n",
    "\n",
    "        # identify and read in corresponding predicted extent probabilities file\n",
    "        extent_prob_predicted_file=os.path.join(prediction_folder,'_'.join([country,'extent_prob',str_year,str_month,chunk_id])+'.tif')\n",
    "        extent_prob_predicted=imageio.imread(extent_prob_predicted_file)\n",
    "\n",
    "        # calculate evaluation scores\n",
    "        accuracy,f1,mcc=get_accuracy_scores(extent_true,boundary_true,extent_prob_predicted)\n",
    "\n",
    "        # scores for all fields\n",
    "        mean_accuracy[str_month].append(accuracy.get()[1])\n",
    "        mean_f1[str_month].append(f1.get()[1])\n",
    "        mean_mcc[str_month].append(mcc.get()[1])\n",
    "    \n",
    "    # mean scores\n",
    "    mean_accuracy[str_month]=np.mean(mean_accuracy[str_month])\n",
    "    mean_f1[str_month]=np.mean(mean_f1[str_month])\n",
    "    mean_mcc[str_month]=np.mean(mean_mcc[str_month])\n",
    "\n",
    "print('mean accuracy: ',mean_accuracy)\n",
    "print('mean F1 score: ',mean_f1)\n",
    "print('mean MCC: ',mean_mcc)\n",
    "\n",
    "highest_mccs=sorted(mean_mcc.items(), key=lambda item: item[1],reverse=True)[0:3]\n",
    "print('The three months with highest MCCs: ',highest_mccs)\n",
    "selected_months=[item[0] for item in highest_mccs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine predictions from selected months, evaluate and export results\n",
    "\n",
    "Field extent and boundary probabilities are averaged over selected months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_mean_acc=[]\n",
    "averaged_mean_f1=[]\n",
    "averaged_mean_mcc=[]\n",
    "# loop through all chunks and average over months\n",
    "for chunk_id in chunk_ids:\n",
    "    extent_average=None\n",
    "    bound_average=None\n",
    "    for i in range(len(selected_months)):\n",
    "        # read in field extent probability geotiff and metadata\n",
    "        extent_prob_predicted_file=os.path.join(prediction_folder,'_'.join([country,'extent_prob',str_year,selected_months[i],chunk_id])+'.tif')\n",
    "        ds_extent = gdal.Open(extent_prob_predicted_file)\n",
    "        geotrans=ds_extent.GetGeoTransform()\n",
    "        proj=ds_extent.GetProjection()\n",
    "        np_extent = ds_extent.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "        # read in boundary probability\n",
    "        bound_prob_predicted_file=extent_prob_predicted_file.replace('extent','bound')\n",
    "        ds_bound=gdal.Open(bound_prob_predicted_file)\n",
    "        np_bound = ds_bound.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "        if i==0:\n",
    "            extent_average=np_extent\n",
    "            bound_average=np_bound\n",
    "        else:\n",
    "            extent_average+=np_extent\n",
    "            bound_average+=np_bound\n",
    "        ds_extent=None\n",
    "        ds_bound=None\n",
    "    # calculate averages\n",
    "    extent_average/=len(selected_months)*1.0\n",
    "    bound_average/=len(selected_months)*1.0\n",
    "    \n",
    "    # find groundtruth extents and boundary probabilities\n",
    "    fn_prefix='_'.join([country,'*extent',chunk_id])+'.tif'\n",
    "    file_extent_true=glob(groundtruth_folder+'/'+fn_prefix)[0]\n",
    "    \n",
    "    # read in ground truth extent and boundary file\n",
    "    extent_true=imageio.imread(file_extent_true)\n",
    "    boundary_true=imageio.imread(file_extent_true.replace('extent','bound'))\n",
    "    \n",
    "    # calculate evaluation scores\n",
    "    accuracy,f1,mcc=get_accuracy_scores(extent_true,boundary_true,extent_average)\n",
    "    averaged_mean_acc.append(accuracy.get()[1])\n",
    "    averaged_mean_f1.append(f1.get()[1])\n",
    "    averaged_mean_mcc.append(mcc.get()[1])\n",
    "    \n",
    "    # export as geotiffs\n",
    "    outname_extent='_'.join([country,'average_extent_prob',str_year,'_'.join(selected_months),chunk_id])+'.tif'\n",
    "    outname_extent=os.path.join(out_folder,outname_extent)\n",
    "    export_geotiff(outname_extent,extent_average,geotrans,proj,gdal.GDT_Float32)\n",
    "\n",
    "    outname_bound='_'.join([country,'average_bound_prob',str_year,'_'.join(selected_months),chunk_id])+'.tif'\n",
    "    outname_bound=os.path.join(out_folder,outname_bound)\n",
    "    export_geotiff(outname_bound,bound_average,geotrans,proj,gdal.GDT_Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy of months-averaged predictions:  0.7508476692005877\n",
      "mean F1 score of months-averaged predictions:  0.8345175457888819\n",
      "mean MCC of months-averaged predictions:  0.28746021573549563\n"
     ]
    }
   ],
   "source": [
    "print('mean accuracy of months-averaged predictions: ',np.mean(averaged_mean_acc))\n",
    "print('mean F1 score of months-averaged predictions: ',np.mean(averaged_mean_f1))\n",
    "print('mean MCC of months-averaged predictions: ',np.mean(averaged_mean_mcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "4dce633ad74794d18e744ff4895033c1217399eea64af39aea26b4d3f3272ece"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
