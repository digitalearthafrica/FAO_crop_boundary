{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook finetunes field extent and boundary probability thresholds used for crop field instance segmentation. It implements grid search to find the thresholds with highest IoUs using validation dataset, then implements crop field instance segmentation using the finetuned thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/numpy/core/getlimits.py:500: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/getlimits.py:500: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "from osgeo import gdal\n",
    "import os\n",
    "import higra as hg\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from skimage import measure\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions from modules\n",
    "from datasets import export_geotiff\n",
    "from instance_segment import InstSegm\n",
    "from evaluation import Calculate_IoUs,get_accuracy_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input folder for predictions\n",
    "input_folder='results/averaged'\n",
    "\n",
    "# input folder for groundtruth field exent chunks\n",
    "groundtruth_folder='../0_Data_preparation/results/groundtruth'\n",
    "\n",
    "# output folder to store instance segmentation results\n",
    "out_folder=input_folder\n",
    "\n",
    "# hyperparameter values: extent and boundary probability thresholds\n",
    "t_exts = np.linspace(0.1, 0.6, 6)\n",
    "t_bounds = np.linspace(0.0, 0.3, 4)\n",
    "\n",
    "# proportion of randomly selected validation samples to be used for thresholds fine-tuning\n",
    "pct_samples=0.8\n",
    "\n",
    "# whether to save results as a pandas dataframe\n",
    "save_grd_search=True\n",
    "\n",
    "country = 'Mozambique'\n",
    "str_year='2021'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify predicted exent and boundary chunks and groundtruth field extents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63 field exent probability images\n"
     ]
    }
   ],
   "source": [
    "files_extent_predictions=glob(input_folder+'/'+country+'*average_extent_prob*.tif')\n",
    "print('Found {} field exent probability images'.format(len(files_extent_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_extent_true=glob(groundtruth_folder+'/*crop_field_extent*.tif')\n",
    "print('Found {} true field extent images'.format(len(files_extent_true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do instance segmentation for a proportion of samples and find thresholds with highest mean IoU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select a proportion of validation chunks\n",
    "- Grid search boundary and extent probability thresholds and calculate IoUs\n",
    "- Find the thresholds with highest median IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly samples from the validation dataset\n",
    "n_samples=len(files_extent_true)\n",
    "random_inds=np.random.choice(n_samples, int(pct_samples*n_samples), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmentation thresholds with highest mIoU:\n",
      " t_ext      0.300000\n",
      "t_bound    0.100000\n",
      "mIoU       0.350159\n",
      "IoU_50     0.211664\n",
      "Name: 9, dtype: float64\n",
      "CPU times: user 5min 53s, sys: 11.2 s, total: 6min 5s\n",
      "Wall time: 5min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mIoUs = [] # median IoU\n",
    "IoU_50s = [] # fraction of fields with >half overlap\n",
    "for t_ext in t_exts:\n",
    "    for t_bound in t_bounds:\n",
    "        best_IoUs_all=[]\n",
    "        # loop through all selected files\n",
    "        for idx in random_inds:\n",
    "            \n",
    "            # groundtruth exent\n",
    "            file_extent_true=files_extent_true[idx]\n",
    "            \n",
    "            # get chunk id\n",
    "            chunk_id='_'.join(os.path.basename(file_extent_true)[:-4].split('_')[-2:])\n",
    "            fn_prefix='_'.join([country,'average_extent_prob',str_year,'*',chunk_id])+'.tif'\n",
    "            \n",
    "            # find corresponding extent prediction chunk\n",
    "            list_files=glob(input_folder+'/'+fn_prefix)\n",
    "            \n",
    "            if len(list_files)>0:\n",
    "                file_exent_prediction=list_files[0]\n",
    "                file_bound_prediction=file_exent_prediction.replace('extent','bound')\n",
    "\n",
    "                # read in files\n",
    "                extent_true=imageio.imread(file_extent_true)\n",
    "                extent_prob=imageio.imread(file_exent_prediction)\n",
    "                bound_prob=imageio.imread(file_bound_prediction)\n",
    "\n",
    "                # do segmentation using current thresholds\n",
    "                instances_predicted=InstSegm(extent_prob, bound_prob, t_ext=t_ext, t_bound=t_bound)\n",
    "                # label connected regions, non-field (-1) will be labelled as 0\n",
    "                instances_predicted= measure.label(instances_predicted, background=-1,return_num=False)\n",
    "\n",
    "                # label groundtruth crop fields\n",
    "                instances_true= measure.label(extent_true, background=-1,return_num=False)\n",
    "\n",
    "                # calculate IoU\n",
    "                best_IoUs, field_sizes=Calculate_IoUs(instances_true, instances_predicted, plot=False)\n",
    "                best_IoUs_all.extend(best_IoUs)\n",
    "        mIoUs.append(np.median(best_IoUs_all))\n",
    "        IoU_50s.append(np.sum(np.array(best_IoUs_all) > 0.5) / len(best_IoUs_all))\n",
    "\n",
    "hp_df = pd.DataFrame({\n",
    "    't_ext': np.repeat(t_exts, len(t_bounds)),\n",
    "    't_bound': np.tile(t_bounds, len(t_exts)),\n",
    "    'mIoU': mIoUs,\n",
    "    'IoU_50': IoU_50s\n",
    "})\n",
    "# save results as a pandas dataframe\n",
    "if save_grd_search:\n",
    "    hp_df.to_csv(os.path.join(out_folder,'grid_search_thresholds.csv'))\n",
    "print('segmentation thresholds with highest mIoU:\\n',hp_df.iloc[hp_df['mIoU'].idxmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do instance segmentation for all samples, evaluate and export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median IoU using the best threholds:  0.3668639053254438\n",
      "IoU_50 using the best threholds:  0.22844617632732586\n",
      "CPU times: user 18.4 s, sys: 631 ms, total: 19 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# use best thresholds\n",
    "t_ext_best=hp_df.iloc[hp_df['mIoU'].idxmax()]['t_ext']\n",
    "t_bnd_best=hp_df.iloc[hp_df['mIoU'].idxmax()]['t_bound']\n",
    "# list of IoUs\n",
    "best_IoUs_all=[]\n",
    "# loop through all validation chunks\n",
    "for file_extent_true in files_extent_true:\n",
    "    # get chunk id\n",
    "    chunk_id='_'.join(os.path.basename(file_extent_true)[:-4].split('_')[-2:])\n",
    "    fn_prefix='_'.join([country,'average_extent_prob',str_year,'*',chunk_id])+'.tif'\n",
    "\n",
    "    # find corresponding extent prediction chunk\n",
    "    list_files=glob(input_folder+'/'+fn_prefix)\n",
    "\n",
    "    if len(list_files)>0:\n",
    "        file_exent_prediction=list_files[0]\n",
    "        \n",
    "        # extract geo information using gdal\n",
    "        ds = gdal.Open(file_exent_prediction)\n",
    "        geotrans=ds.GetGeoTransform()\n",
    "        proj=ds.GetProjection()\n",
    "        ds=None\n",
    "        # corresponding boundary chunk file\n",
    "        file_bound_prediction=file_exent_prediction.replace('extent','bound')\n",
    "\n",
    "        # read in arrays\n",
    "        extent_true=imageio.imread(file_extent_true)\n",
    "        extent_prob=imageio.imread(file_exent_prediction)\n",
    "        bound_prob=imageio.imread(file_bound_prediction)\n",
    "\n",
    "        # do segmentation using selected thresholds\n",
    "        instances_predicted=InstSegm(extent_prob, bound_prob, t_ext=t_ext_best, t_bound=t_bnd_best)\n",
    "        # label connected regions, non-field (-1) will be labelled as 0\n",
    "        instances_predicted= measure.label(instances_predicted, background=-1,return_num=False)\n",
    "\n",
    "        # label groundtruth crop fields\n",
    "        instances_true= measure.label(extent_true, background=-1,return_num=False)\n",
    "\n",
    "        # calculate IoU\n",
    "        best_IoUs, field_sizes=Calculate_IoUs(instances_true, instances_predicted, plot=False)\n",
    "        best_IoUs_all.extend(best_IoUs)\n",
    "        \n",
    "        # export instances as geotiff\n",
    "        outname=os.path.join(out_folder,os.path.basename(file_exent_prediction).replace('extent_prob','field_instance'))\n",
    "        export_geotiff(outname,instances_predicted,geotrans,proj,gdal.GDT_Int16)\n",
    "\n",
    "m_IoU=np.median(best_IoUs_all)\n",
    "IoU_50=np.sum(np.array(best_IoUs_all) > 0.5) / len(best_IoUs_all)\n",
    "print('median IoU using the best threholds: ',m_IoU)\n",
    "print('IoU_50 using the best threholds: ',IoU_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "cdb4f26bf53785eacf4a6dff741c826249ef78a5457602be9aaa7cff4587c238"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
